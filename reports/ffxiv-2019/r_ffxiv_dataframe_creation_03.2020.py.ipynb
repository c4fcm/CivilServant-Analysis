{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# r/ffxiv Experiment Dataframe Creation\n",
    "July 2020\n",
    "\n",
    "J. Nathan Matias and Eric Pennington"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /usr/local/civilservant/platform/logs/CivilServant_production.log\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import inspect, os, sys, copy, pytz, re, glob, csv, uuid, datetime, jsonlines\n",
    "from bloom_filter import BloomFilter\n",
    "\n",
    "os.environ['AIRBRAKE_API_KEY'] = \"ca826dbd1a4594241c239bba825edd9f\" ## EDIT BEFORER USING\n",
    "os.environ['AIRBRAKE_PROJECT_ID'] = \"-1\" ## EDIT BEFORE USING\n",
    "\n",
    "import simplejson as json\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt   # Matplotlib for plotting\n",
    "import matplotlib.dates as md\n",
    "from collections import Counter, defaultdict\n",
    "utc=pytz.UTC\n",
    "\n",
    "ENV = \"production\"\n",
    "os.environ['CS_ENV'] = 'production'\n",
    "BASE_DIR = \"/usr/local/civilservant/platform\"\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "with open(os.path.join(BASE_DIR, \"config\") + \"/{env}.json\".format(env=ENV), \"r\") as config:\n",
    "  DBCONFIG = json.loads(config.read())\n",
    "\n",
    "### LOAD SQLALCHEMY\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import text, and_, or_\n",
    "import sqlalchemy.orm.session\n",
    "import utils.common\n",
    "\n",
    "\n",
    "db_engine = create_engine(\"mysql://{user}:{password}@{host}/{database}\".format(\n",
    "    host = DBCONFIG['host'],\n",
    "    user = DBCONFIG['user'],\n",
    "    password = DBCONFIG['password'],\n",
    "    database = DBCONFIG['database']))\n",
    "DBSession = sessionmaker(bind=db_engine)\n",
    "db_session = DBSession()\n",
    "\n",
    "### LOAD PRAW\n",
    "# import reddit.connection\n",
    "# conn = reddit.connection.Connect(base_dir=BASE_DIR, env=\"jupyter\")\n",
    "# r = conn.connect(controller=\"Jupyter\")\n",
    "\n",
    "from app.models import *\n",
    "\n",
    "### FILTER OUT DEPRECATION WARNINGS ASSOCIATED WITH DECORATORS\n",
    "# https://github.com/ipython/ipython/issues/9242\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning, message='.*use @default decorator instead.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_id = \"2rgs7\"\n",
    "data_dir = \"~/Tresors/CivilServant/projects/CivilServant-reddit/r-ffxiv-2020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Dataset of Posts Appearing In the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_posts = []\n",
    "for row in db_engine.execute(text(\"\"\"\n",
    "select * from experiment_things \n",
    "  JOIN posts on experiment_things.id = posts.id \n",
    "  WHERE object_type=1 \n",
    "    AND (experiment_id=15 OR experiment_id=16)\n",
    "  ORDER BY posts.created ASC;\n",
    "\n",
    "\"\"\")):\n",
    "    post = {}\n",
    "    for key in row.keys():\n",
    "        post[key]=row[key]\n",
    "    metadata = json.loads(row['metadata_json'])\n",
    "    for key in metadata['randomization'].keys():\n",
    "        post[key] = metadata['randomization'][key]\n",
    "    post['treat.number'] = int(post[''])\n",
    "    del post['']\n",
    "    del post['metadata_json']\n",
    "    post['post_data']  = json.loads(post['post_data'])\n",
    "    experiment_posts.append(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12100 posts have been assigned to treatment or control in the experiment.\n",
      "Earliest Date: 2019-07-06 12:26:30\n",
      "Latest Date: 2019-08-24 19:06:05\n"
     ]
    }
   ],
   "source": [
    "print(\"{0} posts have been assigned to treatment or control in the experiment.\".format(len(experiment_posts)))\n",
    "earliest_date = experiment_posts[0]['created']\n",
    "latest_date = experiment_posts[-1]['created']\n",
    "print(\"Earliest Date: {0}\".format(earliest_date))\n",
    "print(\"Latest Date: {0}\".format(latest_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Replies to the Sticky Comment (sticky_comment_ffxiv_07_2019.yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_07_comments = []\n",
    "experiment_08_comments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_07_comments experiment had 0 replies to experiments\n"
     ]
    }
   ],
   "source": [
    "import app.controllers.sticky_comment_experiment_controller as scec\n",
    "import logging\n",
    "\n",
    "## hack: we may not need to actually query PRAW here, so setting it to None\n",
    "r = None\n",
    "\n",
    "experiment = scec.StickyCommentExperimentController(\"sticky_comment_ffxiv_07_2019\", \n",
    "                                                    db_session,\n",
    "                                                    r,\n",
    "                                                    logging.getLogger(\"Analysis\"),\n",
    "                                                    required_keys={}) # another hack\n",
    "experiment_07_comments = experiment.get_comment_objects_for_experiment_comment_replies(\n",
    "    experiment.get_all_experiment_comment_replies()\n",
    ")\n",
    "\n",
    "print(\"experiment_07_comments experiment had {0} replies to experiments\".format(\n",
    "        len(experiment_07_comments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Replies to the Sticky Comment (sticky_comment_ffxiv_08_2019.yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_08_comments experiment had 0 replies to experiments\n"
     ]
    }
   ],
   "source": [
    "import app.controllers.sticky_comment_experiment_controller as scec\n",
    "import logging\n",
    "experiment = scec.StickyCommentExperimentController(\"sticky_comment_ffxiv_08_2019\", \n",
    "                                                    db_session,\n",
    "                                                    r,\n",
    "                                                    logging.getLogger(\"Analysis\"),\n",
    "                                                    required_keys={})\n",
    "experiment_08_comments = experiment.get_comment_objects_for_experiment_comment_replies(\n",
    "    experiment.get_all_experiment_comment_replies()\n",
    ")\n",
    "\n",
    "print(\"experiment_08_comments experiment had {0} replies to experiments\".format(\n",
    "        len(experiment_08_comments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Moderator Actions Between the Earliest Date and One Week After the Final Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49497 moderator actions loaded\n"
     ]
    }
   ],
   "source": [
    "recent_mod_actions = []\n",
    "for row in db_engine.execute(text(\"\"\"\n",
    "SELECT action_data FROM mod_actions \n",
    "    WHERE subreddit_id=\"{0}\" AND \n",
    "          created_utc >= \"{1}\" AND\n",
    "          created_utc <= \"{2}\"\n",
    "    ORDER BY created_utc;\n",
    "\"\"\".format(subreddit_id,\n",
    "           earliest_date,\n",
    "           latest_date +  datetime.timedelta(days=7)))):\n",
    "    mod_action = json.loads(row['action_data'])\n",
    "    mod_action['created'] = utc.localize(datetime.datetime.utcfromtimestamp(mod_action['created_utc']))\n",
    "    recent_mod_actions.append(mod_action)\n",
    "print(\"{0} moderator actions loaded\".format(len(recent_mod_actions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag posts as visible or non-visible based on moderation log\n",
    "Also: create study_posts, which is the dict used to create the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Count: 12100\n",
      "Matched Mod Actions: 4160\n"
     ]
    }
   ],
   "source": [
    "study_posts = {}\n",
    "for post in experiment_posts:\n",
    "    post['visible'] = True\n",
    "    study_posts[post['id']] = post\n",
    "recent_post_count = len(study_posts.values())\n",
    "print(\"Post Count: {0}\".format(recent_post_count))\n",
    "\n",
    "missing_mod_actions = []\n",
    "matched_mod_actions = 0\n",
    "for action in recent_mod_actions:\n",
    "    if action['action'] == \"removelink\":\n",
    "        key = action['target_fullname'].replace(\"t3_\",\"\")\n",
    "        if key in study_posts.keys():\n",
    "            study_posts[key]['visible'] = False\n",
    "            matched_mod_actions += 1\n",
    "        else:\n",
    "            missing_mod_actions.append(key)\n",
    "    elif action['action'] == 'approvelink':\n",
    "        key = action['target_fullname'].replace(\"t3_\",\"\")\n",
    "        if key in study_posts.keys():\n",
    "            study_posts[key]['visible'] = True\n",
    "            matched_mod_actions += 1\n",
    "        else:\n",
    "            missing_mod_actions.append(key)\n",
    "#print(\"Missing Mod Actions: {0}\".format(len(missing_mod_actions)))\n",
    "# print(\"Missing Mod Action Posts: {0}\".format(len(set(missing_mod_actions))))\n",
    "print(\"Matched Mod Actions: {0}\".format(matched_mod_actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Dataset of Comments In the Experiment\n",
    "## Create List of Newcomer Accounts\n",
    "Six months before 2019-07-06 12:26:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 7, 6, 12, 26, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff_time = parser.parse(\"2019-07-06 12:26:30\")\n",
    "cutoff_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffxiv-comments-2019-01.ndjson\n",
      "ffxiv-comments-2019-06.ndjson\n",
      "ffxiv-comments-2019-08.ndjson\n",
      "ffxiv-comments-2019-02.ndjson\n",
      "ffxiv-comments-2019-03.ndjson\n",
      "ffxiv-comments-2019-05.ndjson\n",
      "ffxiv-comments-2019-04.ndjson\n",
      "ffxiv-comments-2019-07.ndjson\n"
     ]
    }
   ],
   "source": [
    "all_accounts = set()\n",
    "for filename in glob.glob(\"ffxiv*.ndjson\"):\n",
    "    print(filename)\n",
    "    with jsonlines.open(filename) as reader:\n",
    "        for comment in reader:\n",
    "            timestamp = datetime.datetime.utcfromtimestamp(comment['created_utc'])\n",
    "            if(timestamp < cutoff_time and \n",
    "               timestamp > cutoff_time - datetime.timedelta(days=30*6)):\n",
    "                all_accounts.add(comment['author'])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61560 total accounts\n"
     ]
    }
   ],
   "source": [
    "print(\"{0} total accounts\".format(len(all_accounts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dict of Backfill Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffxiv-comments-2019-07.ndjson\n",
      "ffxiv-comments-2019-08.ndjson\n",
      "537133 available backfill comments\n"
     ]
    }
   ],
   "source": [
    "backfill_comments = {}\n",
    "\n",
    "for filename in [\"ffxiv-comments-2019-07.ndjson\",\n",
    "                 \"ffxiv-comments-2019-08.ndjson\"]:\n",
    "    print(filename)\n",
    "    with jsonlines.open(filename) as reader:\n",
    "        for comment in reader:\n",
    "            comment['created'] = utc.localize(datetime.datetime.utcfromtimestamp(comment['created_utc']))\n",
    "            comment['body.length'] = len(comment['body'])\n",
    "            comment['body'] = None\n",
    "            comment['body_html'] = None\n",
    "            comment['visible'] = True\n",
    "            backfill_comments[comment['id']] = comment\n",
    "print(\"{0} available backfill comments\".format(len(backfill_comments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Comments Observed by CivilServant during the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49497 comments actions loaded\n"
     ]
    }
   ],
   "source": [
    "dbcomments = {}\n",
    "\n",
    "comment_query = \"\"\"\n",
    "SELECT * FROM comments \n",
    "    WHERE subreddit_id=\"{0}\" AND \n",
    "          created_utc >= \"{1}\" AND\n",
    "          created_utc <= \"{2}\";\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for row in db_engine.execute(text(comment_query.format(subreddit_id,\n",
    "           earliest_date,\n",
    "           latest_date +  datetime.timedelta(days=7)))):\n",
    "    \n",
    "    comment = {}\n",
    "    for key in row.keys():\n",
    "        comment[key] = row[key]\n",
    "    comment_data = json.loads(comment['comment_data'])\n",
    "    for key in comment_data.keys():\n",
    "        comment[key] = comment_data[key]\n",
    "    del comment['comment_data']\n",
    "\n",
    "    comment['created'] = utc.localize(datetime.datetime.utcfromtimestamp(comment['created_utc']))\n",
    "    comment['body.length'] = len(comment['body'])\n",
    "    comment['body'] = None\n",
    "    comment['body_html'] = None\n",
    "    comment['visible'] = True\n",
    "\n",
    "    dbcomments[comment['id']] = comment\n",
    "\n",
    "print(\"{0} comments actions loaded\".format(len(recent_mod_actions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a dict of all comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537133 in all comments\n",
      "438880 in all dbcomments\n",
      "537133 in all backfill_comments\n"
     ]
    }
   ],
   "source": [
    "## all_comments will have a dict of all comments\n",
    "## with dbcomments overwriting backfilled ones\n",
    "## and with keys being the comment ID\n",
    "all_comments = copy.copy(backfill_comments)\n",
    "all_comments.update(dbcomments)\n",
    "\n",
    "print(\"{0} in all comments\".format(len(all_comments)))\n",
    "print(\"{0} in all dbcomments\".format(len(dbcomments)))\n",
    "print(\"{0} in all backfill_comments\".format(len(backfill_comments)))\n",
    "\n",
    "#summary: there are no comments we have that jason didn't observe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Missing Comments from Moderation Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Comments: 31\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "missing_comment_ids = []\n",
    "missing_comment_actions = []\n",
    "for action in recent_mod_actions:\n",
    "    if action['target_fullname'] is not None and \"t1_\" in action['target_fullname']:\n",
    "        link_id = re.search('/r/ffxiv/comments/(.*?)/', action['target_permalink']).group(1)\n",
    "        if action['target_fullname'].replace(\"t1_\", \"\") not in all_comments.keys():\n",
    "            missing_comment_ids.append(action['target_fullname'])\n",
    "            missing_comment_actions.append(action)\n",
    "print(\"Missing Comments: {0}\".format(len(missing_comment_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_comment_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Use Existing Metadata to Integrate Records about Missing Comments Into the Final Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify comments that are replies to sticky comment actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step one: query all experiment_actions that were sticky comments\n",
    "## select action_subject_id from experiment_actions WHERE experiment_id IN (15,16) AND action=\"Intervention\" AND action_subject_id IS NOT NULL;\n",
    "action_query = \"\"\"\n",
    "SELECT action_subject_id FROM experiment_actions \n",
    "    WHERE experiment_id IN (\"{0},{1}\") \n",
    "    AND action_subject_id IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "sticky_comment_ids = []\n",
    "\n",
    "for row in db_engine.execute(text(action_query.format(15,16))):\n",
    "    sticky_comment_ids.append(\"t1_\" + row['action_subject_id'])\n",
    "\n",
    "replies_to_sticky = 0\n",
    "for comment in all_comments.values():\n",
    "    if(comment['parent_id'] in sticky_comment_ids):\n",
    "        replies_to_sticky += 1\n",
    "print(\"{0} replies to stickies\".format(replies_to_sticky))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a time sorted list of comments on the sampled posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "EPOCH = utc.localize(datetime.datetime.utcfromtimestamp(0))\n",
    "\n",
    "class CommentHeapObj(object):\n",
    "    def __init__(self, comment):\n",
    "        self.index = int((comment['created'] - EPOCH).total_seconds())\n",
    "        self.val = comment\n",
    "    def __lt__(self, other):\n",
    "        return self.index < other.index\n",
    "\n",
    "def heapsort(comments):\n",
    "    h = []\n",
    "    for comment in comments:\n",
    "        heapq.heappush(h, CommentHeapObj(comment))\n",
    "    return [heapq.heappop(h).val for i in range(len(h))]\n",
    "\n",
    "all_comments = heapsort(all_comments.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Moderation Actions to Comments, Setting Comments as Visible or Not Visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734 Total moderation actions\n",
      "4482 Comments with moderation actions\n",
      "227 Comments with more than one mod action\n",
      "\n",
      "Summary of Comment Visibility:\n",
      "Counter({True: 533881, False: 3252})\n",
      "Took 3386 actions to set a comment to removed\n",
      "Took 1319 actions to set a comment to approved\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "mod_comment_actions = defaultdict(list)\n",
    "approved_count = 0\n",
    "removed_count = 0\n",
    "total_coments_removed_at_least_once = []\n",
    "comments_with_mod_actions = set()\n",
    "\n",
    "for action in recent_mod_actions:\n",
    "     if action['action'] == \"removecomment\" or action['action'] == \"approvecomment\":\n",
    "            comment_id = action['target_fullname'].replace(\"t1_\", \"\")\n",
    "            mod_comment_actions[comment_id].append(action)\n",
    "            comments_with_mod_actions.add(action['target_fullname'])\n",
    "\n",
    "print(\"{0} Total moderation actions\".format(sum([len(x) for x in mod_comment_actions.values()])))\n",
    "print(\"{0} Comments with moderation actions\".format(len(mod_comment_actions)))\n",
    "print(\"{0} Comments with more than one mod action\".format(len([x for x in mod_comment_actions.values() if len(x)>1])))\n",
    "print(\"\")\n",
    "\n",
    "for comment in all_comments:\n",
    "    if('later_deleted' not in comment.keys()):\n",
    "        comment['later_deleted'] = False\n",
    "        if(comment['author'] ==\"[deleted]\"):\n",
    "            comment['later_deleted'] = True\n",
    "    if comment['id'] in mod_comment_actions.keys():\n",
    "        for action in mod_comment_actions[comment['id']]:\n",
    "            ## many authors are later deleted, so try to \n",
    "            ## add in the author information here, since\n",
    "            ## the moderation log retains the author information\n",
    "            comment['author']  = action['target_author']\n",
    "            if action['action'] ==\"removecomment\":\n",
    "                removed_count += 1\n",
    "                total_coments_removed_at_least_once.append(comment['id'])\n",
    "                comment['visible'] = False\n",
    "            elif action['action'] == \"approvecomment\":\n",
    "                approved_count += 1\n",
    "                comment['visible']  = True\n",
    "print(\"Summary of Comment Visibility:\")\n",
    "print(Counter([x['visible'] for x in all_comments]))\n",
    "print(\"Took {0} actions to set a comment to removed\".format(removed_count))\n",
    "print(\"Took {0} actions to set a comment to approved\".format(approved_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Author Comment Number to All Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_comment_num = defaultdict(int)\n",
    "\n",
    "for comment in all_comments:\n",
    "    comment['author.prev.comments'] = author_comment_num[comment['author']]    \n",
    "    author_comment_num[comment['author']] += 1\n",
    "    \n",
    "    comment['author.prev.comments.list'] = False\n",
    "    if comment['author'] in all_accounts:\n",
    "        comment['author.prev.comments.list'] = True\n",
    "        \n",
    "## now create a first comment variable\n",
    "for comment in all_comments:\n",
    "    comment['newcomer'] = 0\n",
    "    if(comment['author.prev.comments']==0 and comment['author.prev.comments.list']):\n",
    "        comment['newcomer'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Author Removed Count to All Comments\n",
    "# from collections import defaultdict, Counter\n",
    "\n",
    "# author_removed_num = defaultdict(int)\n",
    "\n",
    "# for comment in all_comments:\n",
    "#     comment['author.prev.removed'] = author_removed_num[comment['author']]  \n",
    "#     if(comment['visible']==False):\n",
    "#         author_removed_num[comment['author']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# plt.figure(figsize=(10, 3)) \n",
    "# plt.hist([math.log1p(x['author.prev.removed']) for x in all_comments])\n",
    "# plt.title(\"log1p Number of author's previous comments removed, by comment\", fontsize=\"18\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Post Data into Comments for Analysis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiment_sticky_reply_ids = [x.id for x in experiment_07_comments] + [x.id for x in experiment_08_comments]\n",
    "\n",
    "recent_comments_included = []\n",
    "experiment_comments = []\n",
    "for comment in all_comments:\n",
    "    if(comment['author'] == \"CivilServantBot\"):\n",
    "        experiment_comments.append(comment)\n",
    "        continue\n",
    "    post_id = comment['link_id'].replace(\"t3_\", \"\")\n",
    "    if(post_id in study_posts.keys()):\n",
    "        post = study_posts[comment['link_id'].replace(\"t3_\", \"\")]\n",
    "        post_created = utc.localize(post['created'])\n",
    "        \n",
    "        \n",
    "        ### TODO: assign comment['newcomer'] based on prev.comments and presence in all_accounts\n",
    "        \n",
    "        comment['intervention.reply'] = comment['id'] in all_experiment_sticky_reply_ids\n",
    "        comment['post.created'] = post['created']\n",
    "        comment['minutes.since.post.created'] = (comment['created'] - post_created).total_seconds() / 60.\n",
    "        comment['post.author'] = post['post_data']['author']\n",
    "        comment['post.visible'] = post['visible']\n",
    "        comment['toplevel'] = comment['link_id'] == comment['parent_id']\n",
    "        comment['post.domain'] = post['post_data']['domain']\n",
    "        comment['post.day.num']  = (post_created - utc.localize(datetime.datetime(1970,1,1))).days\n",
    "        comment['day.num'] = (comment['created'] - utc.localize(datetime.datetime(1970,1,1))).days\n",
    "        comment['weekday'] = comment['created'].weekday()\n",
    "        comment['weekend'] = (comment['weekday'] >=6)\n",
    "        comment['post.treatment'] = int(post['treatment'])\n",
    "        comment['post.assign.number']  = int(post['treat.number'])\n",
    "        comment['post.block.id'] = post['block.id']\n",
    "        comment['post.block.size']  = post['block.size']\n",
    "\n",
    "        recent_comments_included.append(comment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Comment Data into Posts for Analysis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in study_posts.values():\n",
    "    post['newcomer.comments'] = 0\n",
    "    post['newcomer.comments.experiment.day'] = 0\n",
    "    post['newcomer.comments.experiment.after'] = 0\n",
    "\n",
    "    post['newcomer.comments.removed'] = 0\n",
    "    post['newcomer.comments.removed.experiment.day'] = 0\n",
    "    post['newcomer.comments.removed.experiment.after'] = 0\n",
    "\n",
    "    post['commenters'] = set()\n",
    "    \n",
    "    post['experiment.day'] = post['created'].replace(hour = 5, minute=0, second=0)\n",
    "    post['experiment.day.next'] = (post['experiment.day'] + datetime.timedelta(days=1))\n",
    "    post['experiment.day.minutes'] = int((post['experiment.day.next'] - post['created']).total_seconds() / 60.)\n",
    "                                                                      \n",
    "    post['num.comments']  = 0\n",
    "    post['num.comments.removed'] = 0\n",
    "    post['num.comments.removed.experiment.day'] = 0\n",
    "    post['num.comments.removed.experiment.after'] = 0\n",
    "    \n",
    "    post['num.comments.experiment.replies'] = 0\n",
    "    post['newcomer.comments.experiment.replies'] = 0\n",
    "                                   \n",
    "    post['weekday'] = post['created'].weekday()\n",
    "    post['weekend'] = (post['weekday'] >=6)\n",
    "    \n",
    "for comment in recent_comments_included:\n",
    "    post = study_posts[comment['link_id'].replace(\"t3_\", \"\")]\n",
    "    post['commenters'].add(comment['author'])\n",
    "    \n",
    "    \n",
    "    if(comment['id'] in all_experiment_sticky_reply_ids):\n",
    "        post['num.comments.experiment.replies'] += 1\n",
    "    else:\n",
    "        post['num.comments'] += 1\n",
    "    \n",
    "    if(comment['visible']!=True):\n",
    "        post['num.comments.removed'] +=1\n",
    "        \n",
    "    ## IF THE COMMENT AUTHOR IS A NEWCOMER\n",
    "    if comment['newcomer'] == 1:\n",
    "        post['newcomer.comments'] += 1\n",
    "        \n",
    "        if(comment['id'] in all_experiment_sticky_reply_ids):\n",
    "            post['newcomer.comments.experiment.replies'] += 1\n",
    "                \n",
    "        if(comment['visible']!=True):\n",
    "            post['newcomer.comments.removed'] += 1\n",
    "\n",
    "for post in study_posts.values():\n",
    "    post['num.commenters'] = len(post['commenters'])\n",
    "    del post['commenters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345387 total comments\n",
      "11129 newcomer comments\n"
     ]
    }
   ],
   "source": [
    "print(\"{0} total comments\".format(len(recent_comments_included)))\n",
    "print(\"{0} newcomer comments\".format(len([x for x in recent_comments_included if x['newcomer'] == 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_cols=['block.id', \n",
    "               'num.commenters', \n",
    "               'num.comments.removed', \n",
    "               'newcomer.comments.removed',\n",
    "               'weekday',\n",
    "               'weekend',\n",
    "               'num.comments',\n",
    "               'newcomer.comments', \n",
    "               'visible', \n",
    "               'created',\n",
    "               'treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([{k: v for k, v in x.items() if k in post_cols} for x in study_posts.values()]).to_csv(\n",
    "    os.path.join(data_dir, \"r-ffxiv-posts-{0}.csv\".format(datetime.datetime.utcnow().strftime('%m.%d.%Y'))),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_cols=['body.length',\n",
    "              'subreddit_id',\n",
    "              'post.assign.number',\n",
    "#              'author',\n",
    "#              'author.prev.removed', \n",
    "              'is_submitter', \n",
    "              'newcomer',\n",
    "              'visible',\n",
    "              'minutes.since.post.created',\n",
    "#              'weekend',\n",
    "#              'weekday',\n",
    "              'post.block.id',\n",
    "              'post.treatment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments: 345387\n",
      "First time comments: 23495\n"
     ]
    }
   ],
   "source": [
    "## filter \n",
    "print(\"Total comments: {0}\".format(len(recent_comments_included)))\n",
    "print(\"First time comments: {0}\".format(len([x for x in recent_comments_included if x['author.prev.comments']==0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([{k: v for k, v in x.items() if k in comment_cols} for x in recent_comments_included if x['author.prev.comments']==0]).to_csv(\n",
    "    os.path.join(data_dir, \"r-ffxiv-newcomer-comments-{0}.csv\".format(datetime.datetime.utcnow().strftime('%m.%d.%Y'))),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
