{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promoting Belonging in r/feminism\n",
    "J. Nathan Matias, June 2020\n",
    "\n",
    "Generating dataset for analysis. Pre-analysis plan at [osf.io/xu258/](https://osf.io/xu258/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import inspect, os, sys, copy, pytz, re, glob, csv, uuid, requests, time\n",
    "os.environ['AIRBRAKE_API_KEY'] = \"1\" ## EDIT BEFORER USING\n",
    "os.environ['AIRBRAKE_PROJECT_ID'] = \"1\" ## EDIT BEFORE USING\n",
    "\n",
    "import simplejson as json\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt   # Matplotlib for plotting\n",
    "import matplotlib.dates as md\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "utc=pytz.UTC\n",
    "\n",
    "ENV = \"production\"\n",
    "os.environ['CS_ENV'] = 'production'\n",
    "BASE_DIR = \"/usr/local/civilservant/platform\"\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "with open(os.path.join(BASE_DIR, \"config\") + \"/{env}.json\".format(env=ENV), \"r\") as config:\n",
    "  DBCONFIG = json.loads(config.read())\n",
    "\n",
    "### LOAD SQLALCHEMY\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import text, and_, or_\n",
    "import sqlalchemy.orm.session\n",
    "import utils.common\n",
    "\n",
    "\n",
    "db_engine = create_engine(\"mysql://{user}:{password}@{host}/{database}\".format(\n",
    "    host = DBCONFIG['host'],\n",
    "    user = DBCONFIG['user'],\n",
    "    password = DBCONFIG['password'],\n",
    "    database = DBCONFIG['database']))\n",
    "DBSession = sessionmaker(bind=db_engine)\n",
    "db_session = DBSession()\n",
    "\n",
    "\n",
    "### LOAD PRAW\n",
    "import praw\n",
    "r = praw.Reddit(user_agent='research code by /u/natematias')\n",
    "\n",
    "from app.models import *\n",
    "\n",
    "### FILTER OUT DEPRECATION WARNINGS ASSOCIATED WITH DECORATORS\n",
    "# https://github.com/ipython/ipython/issues/9242\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning, message='.*use @default decorator instead.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dict2Obj(object):\n",
    "    \"\"\"\n",
    "    Turns a dictionary into a class\n",
    "    \"\"\"\n",
    "    #----------------------------------------------------------------------\n",
    "    def __init__(self, dictionary):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        for key in dictionary:\n",
    "            setattr(self, key, dictionary[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_experiment_objects(experiment_name):\n",
    "    experiment_obj = db_session.query(Experiment).filter(\n",
    "                   Experiment.name == experiment_name\n",
    "                 ).first()\n",
    "    subreddit_id = json.loads(experiment_obj.settings_json)['subreddit_id']\n",
    "    participants = db_session.query(ExperimentThing).filter(\n",
    "                   ExperimentThing.experiment_id == experiment_obj.id\n",
    "               ).all()\n",
    "    usernames = [x.thing_id for x in participants]\n",
    "    participant_comments = db_session.query(Comment).filter(and_(\n",
    "                                Comment.user_id.in_(usernames),\n",
    "                                Comment.subreddit_id == subreddit_id\n",
    "    )).order_by(Comment.created_utc.asc()).all()\n",
    "\n",
    "    actions = db_session.query(ExperimentAction).filter(\n",
    "                                ExperimentAction.experiment_id == experiment_obj.id).all()\n",
    "    \n",
    "    return {\n",
    "        \"participants\": participants,\n",
    "        \"usernames\": usernames,\n",
    "        \"participant_comments\": participant_comments,\n",
    "        \"actions\": actions,\n",
    "        \"subreddit_id\": subreddit_id\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Experiment Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_round_results = return_experiment_objects(\"newcomer_messaging_experiment-feminism-07.2018\")\n",
    "second_round_results = return_experiment_objects(\"newcomer_messaging_experiment-feminism-01.2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = first_round_results['participants'] + second_round_results['participants']\n",
    "usernames = list(set(first_round_results['usernames'] + second_round_results['usernames']))\n",
    "participant_comments = first_round_results['participant_comments'] + second_round_results['participant_comments']\n",
    "actions = first_round_results['actions'] + second_round_results['actions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Modlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_modlog = db_session.query(ModAction).filter(and_(\n",
    "                            ModAction.target_author.in_(usernames),\n",
    "                            ModAction.subreddit_id == first_round_results['subreddit_id']\n",
    ")).order_by(ModAction.created_utc.asc()).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dict of Participants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participant_object():\n",
    "    return {\n",
    "        \"username\": None,\n",
    "        \"treatment\": None,\n",
    "        \"comment_id\": None,\n",
    "        \"submission_id\": None,\n",
    "        \"message_status\": None,\n",
    "        \"randomization\": None,\n",
    "        \"block_id\": None,\n",
    "        \"assignment_datetime\": None,\n",
    "        \"comments\": [],\n",
    "        \"ban_actions\": [],\n",
    "        \"comment_actions\":[],\n",
    "        \"comments_2_weeks\": None,\n",
    "        \"comments_4_weeks\": None,\n",
    "        \"comments_8_weeks\": None,\n",
    "        \"ban_days_2_weeks\": 0,\n",
    "        \"ban_days_4_weeks\": 0,\n",
    "        \"ban_days_8_weeks\": 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## key is username\n",
    "units = defaultdict(participant_object)\n",
    "for participant in participants:\n",
    "    metadata = json.loads(participant.metadata_json)\n",
    "    randomization = metadata['randomization']\n",
    "    units[participant.thing_id]['block_id']      = randomization[\"block.id\"]\n",
    "    units[participant.thing_id]['randomization'] = randomization[\"\"]\n",
    "    units[participant.thing_id]['treatment']     = int(randomization['treatment'])\n",
    "    units[participant.thing_id]['comment_id']    = metadata[\"comment_id\"]\n",
    "    units[participant.thing_id]['submission_id'] = metadata[\"submission_id\"]\n",
    "    units[participant.thing_id]['assignment_datetime'] = participant.created_at\n",
    "    units[participant.thing_id]['message_status'] = metadata['message_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Comments to Dict of Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_comments = sorted(participant_comments, key = lambda x: x.created_utc)\n",
    "for comment in participant_comments:\n",
    "    user_id = comment.user_id\n",
    "    units[user_id]['comments'].append(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Merge Survey Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/civilservant/Tresors/CivilServant/projects/CivilServant-reddit/r-feminism-2018\" ## UPDATE BEFORE RUNNING\n",
    "survey_rows = {}\n",
    "\n",
    "with open(os.path.join(data_dir, \"feminism-post-survey-downloaded-05.12.2020.csv\")) as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        survey_rows[row['the reddit username you used to comment in r/feminism']] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_colnames = {\n",
    "   \"Did you identify as a feminist at the time you made your first comment in r/feminism?\": \"identify_feminist\",\n",
    "   'Select which number, corresponding to the images above, best describes your relationship with r/feminism.': \"community_closeness\",\n",
    "   'If you have any comments or thoughts related to the sub, you may share them with us here:': \"sub_comments\",\n",
    "   \"Timestamp\": \"timestamp\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Many Surveys Overlap with Participants in the Survey?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0} total surveys\".format(len(list(survey_rows.keys()))))\n",
    "\n",
    "matched_usernames = 0\n",
    "for username in set(survey_rows.keys()):\n",
    "    if username in list(units.keys()):\n",
    "        matched_usernames += 1\n",
    "\n",
    "print(\"{0} surveys match to unique participant usernames\".format(matched_usernames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Surveys with Observational Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for username, unit in units.items():\n",
    "    if username in survey_rows.keys():\n",
    "        survey = survey_rows[username]\n",
    "        unit['completed_survey'] = True\n",
    "        for key,value in survey_colnames.items():\n",
    "            unit[value] = survey[key]\n",
    "    else:\n",
    "        unit['completed_survey'] = False\n",
    "        for key, value in survey_colnames.items():\n",
    "            unit[value] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the Number of Days that an account was banned or muted during the observation period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod_action in participant_modlog:\n",
    "    ## used to include mute actions, 'muteuser', 'unmuteuser'\n",
    "    ## but these turned out not to be useful for the study\n",
    "    ## since they don't prevent someone from posting comments\n",
    "    ## and were not specified in the pre-analysis plan\n",
    "    if mod_action.action in ['banuser', 'unbanuser']:\n",
    "        username = mod_action.target_author\n",
    "        units[username]['ban_actions'].append(mod_action)\n",
    "    if mod_action.action in ['removecomment', 'approvecomment']:\n",
    "        units[username]['comment_actions'].append(mod_action)\n",
    "    \n",
    "Counter([len(x['ban_actions']) for x in units.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an account is considered banned or muted during\n",
    "# a given day if they were banned or muted at all\n",
    "# during that 24 hour period\n",
    "\n",
    "#test_units = [x for x in units.values() if len(x['ban_actions'])>0]\n",
    "\n",
    "for unit in units.values(): #units.values():\n",
    "    ban_status = False\n",
    "    ban_datetime = None\n",
    "    next_ban_pointer = 0\n",
    "    \n",
    "    observation_days = [0] * 8*7\n",
    "    \n",
    "    ## ASSIGN OBSERVATION DAYS\n",
    "    for i in list(range(0, len(observation_days))):\n",
    "        obs_date = unit['assignment_datetime'] + datetime.timedelta(days=i)\n",
    "\n",
    "        if(next_ban_pointer < len(unit['ban_actions']) and \n",
    "           unit['ban_actions'][next_ban_pointer].created_utc <= obs_date):\n",
    "            \n",
    "            ban_action = unit['ban_actions'][next_ban_pointer]\n",
    "            \n",
    "            ## these previously included bans and mutes, but \n",
    "            ## mutes are not relevant for this study\n",
    "            if(ban_action.action in ['banuser']):\n",
    "                ban_status = True\n",
    "            elif(ban_action.action in ['unbanuser']):\n",
    "                ban_status = False\n",
    "            \n",
    "            next_ban_pointer += 1\n",
    "            \n",
    "        observation_days[i] = ban_status\n",
    "    \n",
    "    unit['ban_observation_days'] = observation_days\n",
    "    \n",
    "    ## RESET BAN DAY COUNTS\n",
    "    for weeks in [2,3,4,5,6,7,8]:\n",
    "        key = \"ban_days_{0}_weeks\".format(weeks)\n",
    "        unit[key] = 0\n",
    "        \n",
    "    ## AGGREGATE OBSERVATION DAYS INTO COUNTS FOR EACH WEEK DURATION\n",
    "    for i in list(range(0, len(observation_days))):\n",
    "        for weeks in [2,3,4,5,6,7,8]:\n",
    "            if i < weeks*7 and observation_days[i] == True:\n",
    "                key = \"ban_days_{0}_weeks\".format(weeks)\n",
    "                unit[key] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify comments removed in the study and supplement those comments from PushShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPScomments(ids):\n",
    "    url = \"https://api.pushshift.io/reddit/search/comment/?ids={0}\".format(\n",
    "    \",\".join(ids)\n",
    "    )\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comment_actions = []\n",
    "all_comment_ids = [\"t1_{0}\".format(x.id) for x in participant_comments]\n",
    "max_week = 10\n",
    "\n",
    "for identifier, unit in units.items():\n",
    "    assignment_datetime = unit['assignment_datetime']\n",
    "    for action in unit['comment_actions']:\n",
    "        if(action.created_utc > assignment_datetime and\n",
    "           action.created_utc <= assignment_datetime + datetime.timedelta(days = max_week*7)):\n",
    "            all_comment_actions.append(action)\n",
    "print(\"{0} comment actions to query from PushShift\".format(len(all_comment_actions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_modded_ids = list(set([x.target_fullname for x in all_comment_actions]))\n",
    "all_modded_id_usernames = {}\n",
    "for action in all_comment_actions:\n",
    "    all_modded_id_usernames[action.target_fullname.replace(\"t1_\", \"\")] = action.target_author\n",
    "    \n",
    "all_unique_ids = [x for x in all_modded_ids if x not in all_comment_ids]\n",
    "\n",
    "page_size = 500\n",
    "courtesy_delay = 0.25\n",
    "\n",
    "head = 0\n",
    "tail = page_size\n",
    "\n",
    "retrieved_comments = defaultdict(list)\n",
    "\n",
    "while(head <= len(all_unique_ids)):\n",
    "    sys.stdout.write(\".\")\n",
    "    sys.stdout.flush()\n",
    "    ids = all_unique_ids[head:tail]\n",
    "    if(len(ids)>0):\n",
    "        comments = getPScomments(ids)\n",
    "        for comment in comments:\n",
    "            comment['created'] = datetime.datetime.fromtimestamp(comment['created_utc'])\n",
    "            retrieved_comments[comment['id']] = comment\n",
    "    time.sleep(courtesy_delay)\n",
    "    head += page_size\n",
    "    tail += page_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Attempted to retrieve {0} comments\".format(len(all_modded_ids)))\n",
    "print(\"{0} comments retrieved successfully (missing comments were likely permanently removed by reddit)\".format(len(retrieved_comments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge in IDs associated with moderation actions and count the number of comments per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encode the JSON objects as python objects for\n",
    "## merging with the database comment objects\n",
    "for identifier, comment in retrieved_comments.items():\n",
    "    username = all_modded_id_usernames[identifier]\n",
    "    comment['created_utc'] = datetime.datetime.utcfromtimestamp(comment['created_utc'])\n",
    "    units[username]['comments'].append(Dict2Obj(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter([len(x['comments']) for x in units.values()])\n",
    "for unit in units.values():\n",
    "    two_weeks = unit['assignment_datetime'] + datetime.timedelta(days=7*2)\n",
    "    three_weeks = unit['assignment_datetime'] + datetime.timedelta(days=7*3)\n",
    "    four_weeks = unit['assignment_datetime'] + datetime.timedelta(days=7*4)\n",
    "    five_weeks = unit['assignment_datetime'] + datetime.timedelta(days=7*5)\n",
    "    six_weeks = unit['assignment_datetime'] + datetime.timedelta(days=7*6)\n",
    "    seven_weeks = unit['assignment_datetime'] + datetime.timedelta(days=7*7)\n",
    "    eight_weeks = unit['assignment_datetime'] + datetime.timedelta(days=7*8)\n",
    "    nine_weeks = unit['assignment_datetime'] + datetime.timedelta(days=7*9)\n",
    "    ten_weeks = unit['assignment_datetime'] + datetime.timedelta(days=7*10)\n",
    "    unit['comments_2_weeks'] = len([x for x in unit['comments'] if x.created_utc < two_weeks])\n",
    "    unit['comments_3_weeks'] = len([x for x in unit['comments'] if x.created_utc < three_weeks])\n",
    "    unit['comments_4_weeks'] = len([x for x in unit['comments'] if x.created_utc < four_weeks])\n",
    "    unit['comments_5_weeks'] = len([x for x in unit['comments'] if x.created_utc < five_weeks])\n",
    "    unit['comments_6_weeks'] = len([x for x in unit['comments'] if x.created_utc < six_weeks])\n",
    "    unit['comments_7_weeks'] = len([x for x in unit['comments'] if x.created_utc < seven_weeks])\n",
    "    unit['comments_8_weeks'] = len([x for x in unit['comments'] if x.created_utc < eight_weeks])\n",
    "    unit['comments_9_weeks'] = len([x for x in unit['comments'] if x.created_utc < nine_weeks]) \n",
    "    unit['comments_10_weeks'] = len([x for x in unit['comments'] if x.created_utc < ten_weeks])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record the number of comments removed during the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for identifier, unit in units.items():\n",
    "    assignment_datetime = unit['assignment_datetime']\n",
    "    week_counter = 1\n",
    "    week_datetime = assignment_datetime + datetime.timedelta( days= week_counter*7)\n",
    "    \n",
    "    unit_comment_ids = [\"t1_{0}\".format(x.id) for x in unit['comments']]\n",
    "        \n",
    "    ## create columns for week periods\n",
    "    for i in list(range(max_week+1)):\n",
    "        unit[\"removed_comments_{0}_weeks\".format(i)] = 0\n",
    "    \n",
    "    ## create canonical list of comments associated with mod actions\n",
    "    comments_removed = defaultdict(list)\n",
    "    for action in unit['comment_actions']:\n",
    "        if(action.created_utc > assignment_datetime and\n",
    "           action.created_utc <= assignment_datetime + datetime.timedelta(days = max_week*7)):\n",
    "            comments_removed[action.target_fullname].append(action)\n",
    "            all_comment_actions.append(action)\n",
    "        \n",
    "    ## create count of removed comments\n",
    "    for actions in comments_removed.values():\n",
    "        if(actions[-1].action =='removecomment'):\n",
    "            action = actions[0]\n",
    "            comment_week = int((action.created_utc - assignment_datetime).days/7)+1\n",
    "            for i in list(range(2, max_week+1)):            \n",
    "                if comment_week <= i:\n",
    "                    unit['removed_comments_{0}_weeks'.format(i)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Account Mapping between usernames and unique IDs before outputting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_mapping = {}\n",
    "for username in units.keys():\n",
    "    account_mapping[username] = {\n",
    "        \"username\": username,\n",
    "        \"uuid\": uuid.uuid4()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for username, unit in units.items():\n",
    "    unit['id'] = str(account_mapping[username]['uuid'])\n",
    "    unit['ban_observation_days'] = None\n",
    "    unit['comments'] = None\n",
    "    unit['ban_actions'] = None\n",
    "    unit['username']  = None\n",
    "    unit['comment_id'] = None\n",
    "    unit['comment_actions'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(account_mapping.values())).to_csv(\n",
    "    os.path.join(data_dir, \"r-feminism-account-mapping-{0}.csv\".format(datetime.datetime.utcnow().strftime('%m.%d.%Y'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(units.values())).to_csv(\n",
    "    os.path.join(data_dir, \"r-feminism-study-data-merged-{0}.csv\".format(datetime.datetime.utcnow().strftime('%m.%d.%Y'))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
