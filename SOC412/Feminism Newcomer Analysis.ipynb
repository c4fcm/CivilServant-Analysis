{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import inspect, os, sys, copy, pytz, re, glob, math\n",
    "import simplejson as json\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt   # Matplotlib for plotting\n",
    "import matplotlib.dates as md\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import statsmodels.formula.api as smf  # for doing statistical regression\n",
    "import statsmodels.api as sm      # access to the wider statsmodels library, including R datasets\n",
    "from collections import Counter, defaultdict\n",
    "utc=pytz.UTC\n",
    "\n",
    "ENV = \"production\"\n",
    "BASE_DIR = \"/home/nathan/reddit_archive/\"\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "### FILTER OUT DEPRECATION WARNINGS ASSOCIATED WITH DECORATORS\n",
    "# https://github.com/ipython/ipython/issues/9242\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning, message='.*use @default decorator instead.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Comments and Posts from r/feminism from 2017\n",
    "Posts and Comments have been extracted by select_subreddit_posts.py and select_subreddit_comments.py and placed in ~/reddit_archives/feminism_posts_2017.json\n",
    "\n",
    "Source: Felipe Hoffa's Google BigQuery dataset \"fh-bigquery\" from reddit, prepared by Jason Baumgartner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts_filename = \"Feminism_posts_2017.json\"\n",
    "comments_filename = \"feminism_comments_2017.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11205 Posts and 41960 Comments\n",
      "Loaded 11323 Post lines and 47103 Comment lines\n"
     ]
    }
   ],
   "source": [
    "all_posts = []\n",
    "post_ids = set()\n",
    "post_count = 0 \n",
    "with open(os.path.join(BASE_DIR, \"selected_output\", posts_filename), \"r\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        if(item['id'] not in post_ids):\n",
    "            item['created'] = datetime.datetime.utcfromtimestamp(float(item['created_utc']))\n",
    "            all_posts.append(item)\n",
    "            post_ids.add(item['id'])\n",
    "        post_count += 1\n",
    "\n",
    "        \n",
    "all_posts = sorted(all_posts, key = lambda x: x['created'])        \n",
    "\n",
    "all_comments = []\n",
    "comment_ids = set()\n",
    "comment_count = 0\n",
    "with open(os.path.join(BASE_DIR, \"selected_output\", comments_filename), \"r\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        if(item['id'] not in comment_ids):\n",
    "            item['created'] = datetime.datetime.utcfromtimestamp(float(item['created_utc']))\n",
    "            item['body.charlength'] = len(item['body'])\n",
    "            #item['body'] = None\n",
    "            all_comments.append(item)\n",
    "            comment_ids.add(item['id'])\n",
    "        comment_count += 1\n",
    "all_comments = sorted(all_comments, key = lambda x: x['created'])        \n",
    "\n",
    "print(\"Loaded {0} Posts and {1} Comments\".format(len(all_posts), len(all_comments)))\n",
    "print(\"Loaded {0} Post lines and {1} Comment lines\".format(post_count, comment_count))\n",
    "#print(\"Posts have a mean of {0} comments\".format(np.mean([len(x) for x in all_comments.values()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create a Dataset of Previous Posts and Previous Comments by an Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def previous_actions():\n",
    "    return {\"comments\":[], \"posts\":[]}\n",
    "\n",
    "author_records = defaultdict(previous_actions)\n",
    "\n",
    "for item in all_comments:\n",
    "    author_id = item['author']\n",
    "    author_records[author_id]['comments'].append(item)\n",
    "\n",
    "for item in all_posts:\n",
    "    author_id = item['author']\n",
    "    author_records[author_id]['posts'].append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Previous Posts and Comments in the Past 180 Days by Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "comments.........................................\n",
      "posts..........."
     ]
    }
   ],
   "source": [
    "#one_eighty_days in seconds\n",
    "\n",
    "def count_if_eligible(current, comparator):\n",
    "    one_eighty_days = 60*60*24*180\n",
    "    if(current['created'] > comparator['created'] and \n",
    "       (current['created'] - comparator['created']).total_seconds()<one_eighty_days):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "earliest_date = parser.parse(\"Jan 1, 2017 00:00:00\")  + datetime.timedelta(days=180)\n",
    "\n",
    "sys.stdout.write(\"\\ncomments\")\n",
    "sys.stdout.flush()\n",
    "items_processed = 0\n",
    "for item in all_comments:\n",
    "    previous_comments = 0\n",
    "    previous_posts = 0\n",
    "    for comment in author_records[item['author']]['comments']:\n",
    "        if(item['created'] > comment['created']):\n",
    "            previous_comments += count_if_eligible(item, comment) \n",
    "    for post in author_records[item['author']]['posts']:\n",
    "        if(item['created'] > post['created']):\n",
    "            previous_posts += count_if_eligible(item, post)    \n",
    "    items_processed += 1\n",
    "    item['previous.comments'] = previous_comments\n",
    "    item['previous.posts'] = previous_posts\n",
    "    item['eligible'] = item['created'] > earliest_date\n",
    "    \n",
    "    if(items_processed % 1000 == 0):\n",
    "        sys.stdout.write(\".\")\n",
    "        sys.stdout.flush()\n",
    "      \n",
    "sys.stdout.write(\"\\nposts\")\n",
    "sys.stdout.flush()\n",
    "items_processed = 0\n",
    "for item in all_posts:\n",
    "    previous_comments = 0\n",
    "    previous_posts = 0\n",
    "    for comment in author_records[item['author']]['comments']:\n",
    "        if(item['created'] > comment['created']):\n",
    "            previous_comments += count_if_eligible(item, comment) \n",
    "    for post in author_records[item['author']]['posts']:\n",
    "        if(item['created'] > post['created']):\n",
    "            previous_posts += count_if_eligible(item, post)    \n",
    "    items_processed += 1\n",
    "    item['previous.comments'] = previous_comments\n",
    "    item['previous.posts'] = previous_posts\n",
    "    item['eligible'] = item['created'] > earliest_date\n",
    "\n",
    "    if(items_processed % 1000 == 0):\n",
    "        sys.stdout.write(\".\")\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Newcomer Comments and Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eligible_posts = [x for x in all_posts if x['eligible']]\n",
    "post_ids = set([x['id'] for x in eligible_posts])\n",
    "eligible_comments = [x for x in all_comments if x['link_id'].replace(\"t3_\", \"\") in post_ids]\n",
    "\n",
    "#eligible_comments = [x for x in all_comments if x['eligible']]\n",
    "days_in_dataset = (all_posts[-1]['created'] - eligible_posts[0]['created']).total_seconds() / 60. / 60. / 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5246371920350995"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in eligible_posts if x['previous.posts']==0]) / len(eligible_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.228853460465698 eligible first-time posts per day in r/Feminism\n",
      "2017-06-30 00:09:20\n"
     ]
    }
   ],
   "source": [
    "print(\"{0} eligible first-time posts per day in r/Feminism\".format(len([x for x in eligible_posts if x['previous.posts']>0]) / days_in_dataset))\n",
    "print(eligible_posts[0]['created'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Write to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(eligible_posts).to_csv(\"feminism/feminism_posts_06.30.2017-12.31.2107.csv\")\n",
    "pd.DataFrame(eligible_comments).to_csv(\"feminism/feminism_comments_on_posts_with_body_06.30.2017-12.31.2107.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#eligible_comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
